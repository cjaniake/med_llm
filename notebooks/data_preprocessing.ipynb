{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the input dataset\n",
    "GOOGLE_DRIVE_DATASET_URL = (\n",
    "    \"https://drive.google.com/file/d/1vXyLOFRc98f097x4CrK9gOOb3JsKvPmN/view?usp=sharing\"\n",
    ")\n",
    "FILE_ID = re.search(\"/file/d/(.*)/view\", GOOGLE_DRIVE_DATASET_URL).group(1)\n",
    "DOWNLOAD_URL = f\"https://drive.usercontent.google.com/download?id={FILE_ID}&export=download&authuser=0&confirm=t\"\n",
    "original_dataset = pd.read_csv(DOWNLOAD_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is (are) Glaucoma ?</td>\n",
       "      <td>Glaucoma is a group of diseases that can damag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is (are) Glaucoma ?</td>\n",
       "      <td>The optic nerve is a bundle of more than 1 mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is (are) Glaucoma ?</td>\n",
       "      <td>Open-angle glaucoma is the most common form of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who is at risk for Glaucoma? ?</td>\n",
       "      <td>Anyone can develop glaucoma. Some people are a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How to prevent Glaucoma ?</td>\n",
       "      <td>At this time, we do not know how to prevent gl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         question  \\\n",
       "0        What is (are) Glaucoma ?   \n",
       "1        What is (are) Glaucoma ?   \n",
       "2        What is (are) Glaucoma ?   \n",
       "3  Who is at risk for Glaucoma? ?   \n",
       "4       How to prevent Glaucoma ?   \n",
       "\n",
       "                                              answer  \n",
       "0  Glaucoma is a group of diseases that can damag...  \n",
       "1  The optic nerve is a bundle of more than 1 mil...  \n",
       "2  Open-angle glaucoma is the most common form of...  \n",
       "3  Anyone can develop glaucoma. Some people are a...  \n",
       "4  At this time, we do not know how to prevent gl...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count questions\n",
    "\n",
    "Count number of occurrences of each question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count\n",
       "1     14092\n",
       "2       691\n",
       "3        93\n",
       "4        40\n",
       "5        18\n",
       "6        19\n",
       "7         6\n",
       "8         4\n",
       "9         4\n",
       "10        3\n",
       "11        2\n",
       "12        4\n",
       "13        2\n",
       "14        1\n",
       "19        1\n",
       "20        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset.question.value_counts().value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate duplicates\n",
    "\n",
    "Let's eliminate rows with duplicated questions and answers.  \n",
    "The reason is that it would be hard to deal with duplicate questions in the evaluation.  \n",
    "Even if we control the training / test split to avoid that a given question is on both datasets, to avoid data leakage, we would still have different answers to the same questions, which is potentially a problem for the scoring of model responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16406, 2)\n",
      "(16358, 2)\n"
     ]
    }
   ],
   "source": [
    "print(original_dataset.shape)\n",
    "print(original_dataset.drop_duplicates().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = original_dataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.83% of questions appear more than once after removing duplicates\n"
     ]
    }
   ],
   "source": [
    "question_occurence_count = original_dataset.question.value_counts()\n",
    "print(\n",
    "    f\"{(question_occurence_count > 1).sum() / len(question_occurence_count) * 100:.2f}% of questions appear more than once after removing duplicates\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique questions: 14981\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total unique questions: {len(original_dataset.question.unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess correct answers\n",
    "\n",
    "We would like each question to have only one answer.  \n",
    "If we have more than one answer to a question, we will use a language model to combine the answers into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARIZE_ANSWERS_PROMPT = \"\"\"\n",
    "You are a chatbot programmed to help users with medical issues.\n",
    "I have a question from a user and a couple of texts that are related to the question.\n",
    "I want you to summarize the texts producing a concise but detailed response to the user question.\n",
    "Every important piece of information contained in the texts should be included in the summary.\n",
    "You cannot use any external data source, only the data that is provided in the prompt.\n",
    "In the end please add a disclaimer that you can not provide direct medical diagnoses.\n",
    "The format of the response should be plain text, with no title and avoid using bullet points.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\"\"\"\n",
    "\n",
    "DISCLAIMER = \"Disclaimer: This information is for educational purposes only and should not be considered medical advice.  I cannot provide diagnoses.  Always consult with a qualified healthcare professional for any health concerns or before making any decisions related to your medical care.\"\n",
    "\n",
    "\n",
    "def produce_synthetic_summary(question, answers):\n",
    "    prompt = SUMMARIZE_ANSWERS_PROMPT.format(\n",
    "        question=question, context=\"\\n\".join(answers)\n",
    "    )\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_partial(result, filename):\n",
    "    with open(filename, \"a\") as f:\n",
    "        json.dump(result, f)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question:What are the treatments for Heart Failure ?\n",
      "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n",
      "Error processing question:What are the treatments for Sarcoidosis ?\n",
      "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n",
      "Error processing question:What causes Hemochromatosis ?\n",
      "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n"
     ]
    }
   ],
   "source": [
    "correct_answers_data = []\n",
    "for question, question_data in original_dataset.groupby(\"question\"):\n",
    "    try:\n",
    "        if len(question_data) > 1:\n",
    "            response = produce_synthetic_summary(question, question_data.answer)\n",
    "            result = {\"question\": question, \"answer\": response}\n",
    "        else:\n",
    "            response = str(question_data.answer.iloc[0]) + \"\\n\" + DISCLAIMER\n",
    "            result = {\"question\": question, \"answer\": response}\n",
    "        save_partial(result, \"correct_answers_partial.jsonl\")\n",
    "        correct_answers_data.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing question:{question}\\n{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_answers = pd.DataFrame(correct_answers_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate incorrect answers\n",
    "\n",
    "To perform policy optimization in the model we must provide a correct answer and an incorrect answer for each question.  \n",
    "We are going to use a language model to generate the incorrect answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INCORRECT_ANSWER_PROMPT = \"\"\"\n",
    "You are a data annotation expert working on an initiative to build a preference optimization dataset.\n",
    "I have a question from a user and a couple of texts that are related to the question.\n",
    "I want you to generate a wrong response, with incorrect facts, so we can use it as the rejected answer.\n",
    "The answer is supposed to be wrong, but realistic.\n",
    "You cannot use any external data source, only the data that is provided in the prompt.\n",
    "The format of the response should be plain text, with no title and avoid using bullet points.\n",
    "Do not add any note saying that the response is incorrect, this is training data for a model, not a response to a human user.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\"\"\"\n",
    "\n",
    "\n",
    "def produce_incorrect_answer(question, answers):\n",
    "    prompt = INCORRECT_ANSWER_PROMPT.format(\n",
    "        question=question, context=\"\\n\".join(answers)\n",
    "    )\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing question:What is (are) Emery-Dreifuss muscular dystrophy, X-linked ?\n",
      "sequence item 0: expected str instance, float found\n",
      "Error processing question:What is (are) Emery-Dreifuss muscular dystrophy, dominant type ?\n",
      "sequence item 0: expected str instance, float found\n",
      "Error processing question:What is (are) Familial HDL deficiency ?\n",
      "sequence item 0: expected str instance, float found\n",
      "Error processing question:What is (are) HELLP syndrome ?\n",
      "sequence item 0: expected str instance, float found\n",
      "Error processing question:What is (are) X-linked lymphoproliferative syndrome ?\n",
      "sequence item 0: expected str instance, float found\n"
     ]
    }
   ],
   "source": [
    "incorrect_answers_data = []\n",
    "for question, question_data in original_dataset.groupby(\"question\"):\n",
    "    try:\n",
    "        response = produce_incorrect_answer(question, question_data.answer)\n",
    "        result = {\"question\": question, \"incorrect_answer\": response}\n",
    "        save_partial(result, \"incorrect_answers_partial.jsonl\")\n",
    "        incorrect_answers_data.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing question:{question}\\n{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_answers = pd.DataFrame(incorrect_answers_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat(\n",
    "    [correct_answers.set_index(\"question\"), incorrect_answers.set_index(\"question\")],\n",
    "    axis=1,\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"preprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload results to Google Drive\n",
    "\n",
    "Results uploaded to Google Drive:  \n",
    "[https://drive.google.com/file/d/1jlG-__9zwHB_USs5q2D7ipb4SV0TJFBe/view?usp=sharing](https://drive.google.com/file/d/1jlG-__9zwHB_USs5q2D7ipb4SV0TJFBe/view?usp=sharing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
